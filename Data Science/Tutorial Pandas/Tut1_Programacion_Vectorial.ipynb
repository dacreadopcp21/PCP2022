{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fuente : Adrián Soto IIC2413 - Minería de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inducción a Minería de Datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de datos con Python\n",
    "\n",
    "En esta clase veremos la herramienta de análisis de datos `pandas`. Esta herramienta es una librería que permite hacer análisis y limpieza de datos en Python. Está diseñada para trabajar con datos tabulares y heterogéneos. También es utilizada en conjunto con otras herramientas para hacer _Data Science_ como `NumPy`, `SciPy`, `matplotlib` y `scikit-learn`. El objetivo de esta clase/tutorial es tener nociones básicas de la librería `pandas` y conocer cómo esta puede hacer uso de un motor SQL.\n",
    "\n",
    "### Outline\n",
    "\n",
    "En esta clase vamos a ver:\n",
    "\n",
    "- Una introducción a la librería `NumPy`.\n",
    "- Tópicos básicos de la librería `Pandas`:\n",
    " - El tipo `Series`\n",
    " - El tipo `DataFrame`\n",
    " - Proyecciones y filtros en un `DataFrame`\n",
    " - Resumen de los datos\n",
    " - Manejar nulos\n",
    " - Agregación\n",
    " - Índices jerárquicos\n",
    " - Joins\n",
    "- Visualización rápida con `matplotlib`\n",
    "- Una introducción a la librería `Scipy`\n",
    "- Consejos de eficiencia \n",
    "\n",
    "### Requisitos\n",
    "\n",
    "Para esta clase vamos a utilizar Python3 y algunas librerías externas. Las vamos a instalar utilizando pip:\n",
    "\n",
    "```\n",
    "pip3 install --upgrade jupyter matplotlib numpy pandas scipy scikit-learn time seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy\n",
    "\n",
    "`NumPy` es una librería para hacer computos numéricos en Python. Es la base de muchas otras librerías científicas. Entre otras cosas, nos permite:\n",
    "\n",
    "- Utilizar arreglos multidimensionales.\n",
    "- Utilizar funciones matemáticas.\n",
    "- Utilizar herramientas de álgebra lineal.\n",
    "\n",
    "Necesitamos conocer esta librería (en concreto, el manejo de arreglos) para poder entender el funcionamiento de `pandas`. Para comenzar a trabajar vamos a importar la librería y crear un pequeño arreglo de elementos aleatorios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.randn(2,4)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ponderar por un escalar\n",
    "A diferencia de una lista, podemos hacer operaciones matriciales, como multiplicar el arreglo `data` por un escalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.multiply(data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suma\n",
    "o sumarle una matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data + data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear arreglos\n",
    "\n",
    "Podemos crear arreglos a partir de una lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [1, 1, 2, 3, 5]\n",
    "arr1 = np.array(data1)\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = [[1, 1, 2, 3], [5, 8, 13, 21]]\n",
    "arr2 =np.array(data2)\n",
    "arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para preguntar el número de dimensiones utilizamos `ndim`. Para preguntar las dimensiones utilizamos `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices \n",
    "- Invertir \n",
    "- Trasponer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = np.matrix(arr2)\n",
    "mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1.I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accediendo a elementos\n",
    "\n",
    "Para obtener un elemento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos acceder de esta forma también.\n",
    "arr2[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos acceder de esta forma también.\n",
    "arr2[1, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los arreglos son mutables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1[3] = 300\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2[1, 2] = 100\n",
    "arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arange\n",
    "\n",
    "También tenemos un equivalente a `range` llamado `arange`, pero que genera un arreglo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones sobre arreglos\n",
    "\n",
    "Algunas operaciones que se pueden hacer sobre un arreglo son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elevar elementos de un arreglo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elevar al cuadrado\n",
    "\n",
    "arr * arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Elevar al cuadrado\n",
    "\n",
    "np.power(arr, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(arr + 1) - arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arr ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return stt.norm.pdf(x, (0.5))\n",
    "\n",
    "norm(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquemos la funcion norm a cada elemento del arreglo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr =  np.random.randn(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "\n",
    "for x in arr:\n",
    "    l.append(norm(x))\n",
    "    \n",
    "l = np.array(l)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Slices_\n",
    "\n",
    "Podemos extraer partes de un arreglo tal como en las listas. También podemos usar esto para cambiar los valores de dichos elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(3,15)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[3:6] = ':)'\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexando con booleanos\n",
    "\n",
    "Podemos utilizar comparaciones booleanas con los arreglos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([0, 0, 1, 1, 2, 2])\n",
    "arr == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y usarlo para acceder a valores en otros arreglos. Vamos a crear un arreglo multidimensional e ingresar el arreglo anterior como índice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.random.randn(6, 3)\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con ello dejamos las filas en donde su número es igual al valor 1 en el arreglo arr\n",
    "\n",
    "arr2[arr == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y también podemos negar la condición:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2[~(arr == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transponer un arreglo\n",
    "\n",
    "Es posible obtener la transpuesta de un arreglo rápidamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randn(5, 3)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otras funciones estadisticas básicas\n",
    "\n",
    "Tenemos acceso a algunas funciones de estadística básicas. Por ejemplo `sum`, `mean` y `std` nos permiten respectivamente sacar la suma, el promedio y la desviación estándar de un arreglo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randn(10000)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos ordenar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.sort()\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y pedir elementos distintos: (set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([0, 0, 1, 1, 2, 2])\n",
    "np.unique(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Para comenzar con `pandas` estudiaremos los tipos `Series` y `DataFrame`. Partimos importando la librería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series\n",
    "\n",
    "Vamos a partir instanciando objetos de tipo `Series`. Estos objetos son como arreglos unidimensionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([1, 3, -4, 7])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para un objeto de tipo `Series` podemos agregar un label a sus índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([1, 3, -4, 7], index=['d', 'c', 'b', 'a'])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj['c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos seleccionar varios elementos según el label de su índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[['c', 'a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[[0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer filtros pasando un arreglo de _booleanos_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[obj > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos lo que significaba la comparación `obj > 2` en `NumPy`. Esta comparación era una arreglo con el mismo largo que `obj` que tenía el valor `True` en todas las posiciones con valor mayor a 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj > 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que en `obj[obj > 2]` se muestran sólo las filas en la que el arreglo anterior era `True`.\n",
    "\n",
    "Finalmente, podemos crear un objeto `Series` a partir de un diccionario. Supongamos el siguiente diccionario de personas junto a su edad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = {'Alice': 20, 'Bob': 17, 'Charles': 23, 'Dino': 50}\n",
    "people_series = pd.Series(people)\n",
    "people_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "\n",
    "Un objeto de tipo `DataFrame` representa una tabla, en que cada una de sus columnas representa un tipo. Vamos a construir una tabla a partir de un diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_chile = {'name': ['Metropolitana', 'Valparaiso', 'Biobío', 'Maule', 'Araucanía', 'O\\'Higgins'],\n",
    "             'pop': [7112808, 1815902, 1538194, 1044950, 957224, 914555],\n",
    "             'pib': [24850, 14510, 13281, 12695, 11064, 14840]}\n",
    "frame = pd.DataFrame(reg_chile)\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar la función `head` para tener sólo las 5 primeras columnas del Data Frame. En este caso no es mucho aporte, pero para un Data Frame más grande no puede servir para ver cómo vienen los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos proyectar valores pasando el nombre de las columnas que deseamos dejar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[['name', 'pop']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos seleccionar una determinada fila con la función `iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar la misma idea de filtros vista anteriormente. Por ejemplo, vamos a dejar sólamente las columnas con población mayor a 1.000.000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[frame['pop'] > 1000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer filtros con `&` para hacer un `AND`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[(frame['pop'] > 1000000) & (frame['pib'] < 20000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y podemos usar `|` para hacer un `OR`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[(frame['name'] == 'Metropolitana') | (frame['name'] == 'Valparaiso')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen muchas formas de crear y operar sobre un `DataFrame`. Puedes revisar la documentación para encontrar más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orden sobre un Data Frame\n",
    "\n",
    "Para ordenar un objeto `DataFrame` usamos la función `sort_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sort_values(by=['pib'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si necesitamos ordenar por más de una columna, podemos pasar un arreglo al argumento `by`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {'name': ['Metropolitana', 'Valparaiso', 'Biobío', 'Maule', 'Araucanía', 'O\\'Higgins'],\n",
    "             'col1': [1, 1, 2, 3, 2, 3],\n",
    "             'col2': [24850, 14510, 13281, 12695, 11064, 14840]}\n",
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describiendo los datos\n",
    "\n",
    "La librería `pandas` tiene varias funciones que nos permiten obtener descripciones y resúmenes de los datos. Vamos a ver algunos ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando datos externos\n",
    "\n",
    "En `pandas` es posible importar datos en formato `.csv`, `.xlsx` entre otros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versión alternativa: Abrir un archivo csv en nuestro computador:\n",
    "\n",
    "Necesitaremos tener alojado el archivo de la base de datos en la misma carpeta donde se encuntra corriendo el archivo de jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame = pd.read_csv(\"comunas.csv\", names=[\"cod\", \"nombre\", \"provincia\", \"region\", \"superficie\",\n",
    "                                               \"poblacion\", \"densidad\", \"idh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta tabla tenemos valores nulos. Vamos a buscarlos. Primero vamos a encontrar todas las filas que contengan algún nulo, para luego filtrar por ese arreglo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "com_frame.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame[com_frame.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` tiene métodos auxiliares para lidiar con datos faltantes. Uno es eliminar aquellas filas con la función `dropna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "com_cleaned = com_frame.dropna()\n",
    "com_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O podemos tomar una opción menos radical, que es reemplazar los nulos por un valor en particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "com_frame = com_frame.fillna(0)\n",
    "com_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "com_frame = pd.read_csv(\"comunas.csv\", names=[\"cod\", \"nombre\", \"provincia\", \"region\", \"superficie\",\n",
    "                                               \"poblacion\", \"densidad\", \"idh\"])\n",
    "for col in ['cod', 'superficie', 'poblacion', 'densidad', 'idh']:\n",
    "    com_frame[col] = com_frame[col].fillna(com_frame[col].mean())\n",
    "\n",
    "com_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen muchas otras opciones para limpiar los datos, pero no los veremos en este tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregación\n",
    "\n",
    "Vamos a ver unos ejemplos para agregar datos utilizando `pandas`. Lo primero que haremos será agregar el nombre de las columnas al Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "com_frame.columns = ['cod', 'nombre', 'prov', 'reg', 'sup', 'pobl', 'dens', 'idh']\n",
    "com_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a obtener la cantidad de habitantes por región."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "com_frame['pobl'].groupby(com_frame['reg']).sum() # Ojo! esto retorna un objeto Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos preguntar cuantos elementos hay por grupo. En este caso obtendríamos el número de comunas por región."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame['pobl'].groupby(com_frame['reg']).size() # Ojo! esto retorna un objeto Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame['pobl'].groupby([com_frame['prov'], com_frame['reg']]).sum() # Ojo! esto retorna un objeto Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En `pandas` se pueden hacer operaciones mucho más complejas, pero no veremos nada avanzado en esta ocasión. Puedes revisar la documentación para ver que más puedes hacer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficando los datos\n",
    "\n",
    "Una de las ventajas de trabajar con `pandas` es que tenemos acceso rápido a herramientas de visualización. Una de ellas es la librería `matplotlib`. Vamos a ver un ejemplo rápido, haciendo un gráfico de barras de los habitantes por región."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ajustamos el tamaño del gráfico\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "plt.title('Población por región')\n",
    "pop_by_comune = com_frame['pobl'].groupby(com_frame['reg']).sum()\n",
    "plt.bar(pop_by_comune.keys(), pop_by_comune)\n",
    "\n",
    "# Ajustamos la rotación de los labels\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Índices jerárquicos\n",
    "\n",
    "Podemos instanciar objetos de la clase `DataFrame` en que los índices son jerárquicos. Veamos un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_multindex = pd.DataFrame(np.arange(12).reshape(4, 3), \n",
    "                    index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],\n",
    "                    columns=['c1', 'c2', 'c3']) \n",
    "\n",
    "# La función reshape en este \n",
    "# caso distribuye los doce elementos \n",
    "# en una tabla de 4 filas y tres columnas\n",
    "\n",
    "data_multindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_multindex.iloc[0] # Esto nos arroja la primera fila."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos localizar por índice, usamos la función `loc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_multindex.loc['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_multindex.loc['a'].loc[2] # La función loc accede según el label del índice, no la posición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joins\n",
    "\n",
    "Podemos hacer _joins_ sobre los Data Frames. Partamos con un ejemplo sencillo de dos objetos de tipo `DataFrame` que comparten el nombre de un atributo en el que se desea hacer _join_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
    "                    'data1': np.arange(7)})\n",
    "\n",
    "df2 = pd.DataFrame({'key': ['a', 'b'],\n",
    "                    'data2': np.arange(8, 10)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la operación anterior, omitimos indicar explícitamente el atributo sobre el que estamos haciendo join. Para indicarlo hacemos lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
    "                    'data1': np.arange(7)})\n",
    "\n",
    "df2 = pd.DataFrame({'key': ['a', 'b', 'd', 'a'],\n",
    "                    'data2': np.arange(8, 12)})\n",
    "\n",
    "pd.merge(df1, df2, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de que los atributos se llamen de distinta forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'key1': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
    "                    'data1': np.arange(7)})\n",
    "df2 = pd.DataFrame({'key2': ['a', 'b', 'd', 'a'],\n",
    "                    'data2': np.arange(8, 12)})\n",
    "\n",
    "pd.merge(df1, df2, left_on='key1', right_on='key2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de necesitar un _Outer Join_, podemos indicarlo con el argumento `how`. Puede ser `'left'`, `'right'` o `'outer'`. Veamos un ejemplo de _Left Outer Join_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'key1': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
    "                    'data1': np.arange(7)})\n",
    "df2 = pd.DataFrame({'key2': ['a', 'b', 'd', 'a'],\n",
    "                    'data2': np.arange(8, 12)})\n",
    "\n",
    "pd.merge(df1, df2, left_on='key1', right_on='key2', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de querer un _join_ por más de un argumento, puedo indicar una lista de atributos. También puedes renombrar atributos en el caso de que su nombre sea igual en ambos Data Frame y no quieras generar conflictos. Esto lo puedes hacer mediante el argumento `suffixes`. Para ver más puedes consultar la documentación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo último que veremos es cómo hacer un _join_ utilizando una de los índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'key': ['a', 'b', 'a', 'a', 'b', 'c'],\n",
    "                    'value': np.arange(6)})\n",
    "\n",
    "df2 = pd.DataFrame({'dvalue': [10, 20]}, index=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, left_on='key', right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puedes utilizar `merge` con índices jerárquicos. Puedes buscar más información en la documentación de `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "datos = pd.read_csv(\"Data_Ayudantia_1\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datos.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como saber cuantos datos nulos hay?\n",
    "datos.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos sin duplicados\n",
    "def get_values(df, X):\n",
    "    print(\"{}\".format(X))\n",
    "    values = df[X].drop_duplicates().values\n",
    "    print(values,'\\n')\n",
    "    return values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alto_plataforma = get_values(datos, 'alto_plataforma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener solo los valores numéricos\n",
    "def get_numbers(candidates):\n",
    "    values = np.array(list(set(['.'.join(re.findall(r'\\d+',str(value))) for value in candidates])))\n",
    "    values = np.array([value for value in values if len(value)>0]).astype(float).round(1)\n",
    "    values.sort()\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_numbers(alto_plataforma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alto_plataforma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay nunmeros en el elemento?\n",
    "def num_there(s):\n",
    "    return any(i.isdigit() for i in str(s))\n",
    "\n",
    "#obtener string dentro del arreglo\n",
    "def get_strings(candidates):\n",
    "    values = np.array(list(set([str(value).strip().lower() for value in candidates if not num_there(value)])))\n",
    "    values.sort()\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_strings(alto_plataforma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_there(alto_plataforma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy\n",
    "\n",
    "`Scipy` es una librería complementaria a `numpy`, la cual contiene una serie de algoritmos matemáticos para manipular y visualizar datos. Sus principales utilidades son: \n",
    "\n",
    "    - Optimización\n",
    "    - Manejo de distribuciones de probabilidad \n",
    "    - Algoritmos de clustering\n",
    "    - Solvers de cálculo\n",
    "    \n",
    "En este curso, utilizaremos esta herramienta para todas las áreas mencionadas anteriormente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuciones de probabilidad\n",
    "\n",
    "En este caso trabajaremos con datos generados a través de una `distribución normal``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stt\n",
    "\n",
    "# Generamos los datos \n",
    "\n",
    "data = stt.norm.rvs(loc=0, scale=1, size=10000, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la ayuda de la librería `matplotlib` podemos ratificar que los datos son normales haciéndo un histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data, density=True, histtype='stepfilled', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra librería muy útil para hacer visualizaciones es `seaborn`. Esta herramienta permite hacer gráficos más estilizados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado un set de puntos, también es posible evaluarlos bajo una distribución en particular con `scipy`. Esto se hace mediante la función cdf. Es importante mencionar que esta librería (al igual que otras como `sklearn`) son capaces de trabajar con `arrays` y no solo un datos en particular. Es decir, podemos entregar arreglos de datos como input a la hora de querer evaluar muchos datos en una distribución en particular. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos puntos entre -30 y 50 con una densidad de 0.01\n",
    "\n",
    "x = np.arange(-30, 50, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos los valores de los puntos en las distintas distribuciones \n",
    "\n",
    "gamma = stt.gamma(6, 0, 2).pdf(x)\n",
    "laplace = stt.laplace(10, 5.8).pdf(x)\n",
    "normal = 3*stt.norm(10, 15).pdf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Graficar los puntos \n",
    "\n",
    "plt.title('Gráfico ejemplo')\n",
    "plt.plot(x, laplace, label='Lapalce')\n",
    "plt.plot(x, gamma, label='Gamma')\n",
    "plt.plot(x, normal, label='Normal')\n",
    "plt.xlabel('eje x')\n",
    "plt.ylabel('eje y')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot  Multivariate Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import ion, figure, scatter, draw\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def plot_point_cov(points, nstd=2, ax=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plots an `nstd` sigma ellipse based on the mean and covariance of a point\n",
    "    \"cloud\" (points, an Nx2 array).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        points : An Nx2 array of the data points.\n",
    "        nstd : The radius of the ellipse in numbers of standard deviations.\n",
    "            Defaults to 2 standard deviations.\n",
    "        ax : The axis that the ellipse will be plotted on. Defaults to the \n",
    "            current axis.\n",
    "        Additional keyword arguments are pass on to the ellipse patch.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A matplotlib ellipse artist\n",
    "    \"\"\"\n",
    "    pos = points.mean(axis=0)\n",
    "    cov = np.cov(points, rowvar=False)\n",
    "    return plot_cov_ellipse(cov, pos, nstd, ax, **kwargs)\n",
    "\n",
    "def plot_cov_ellipse(cov, pos, nstd=2, ax=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plots an `nstd` sigma error ellipse based on the specified covariance\n",
    "    matrix (`cov`). Additional keyword arguments are passed on to the \n",
    "    ellipse patch artist.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        cov : The 2x2 covariance matrix to base the ellipse on\n",
    "        pos : The location of the center of the ellipse. Expects a 2-element\n",
    "            sequence of [x0, y0].\n",
    "        nstd : The radius of the ellipse in numbers of standard deviations.\n",
    "            Defaults to 2 standard deviations.\n",
    "        ax : The axis that the ellipse will be plotted on. Defaults to the \n",
    "            current axis.\n",
    "        Additional keyword arguments are pass on to the ellipse patch.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A matplotlib ellipse artist\n",
    "    \"\"\"\n",
    "    def eigsorted(cov):\n",
    "        vals, vecs = np.linalg.eigh(cov)\n",
    "        order = vals.argsort()[::-1]\n",
    "        return vals[order], vecs[:,order]\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    vals, vecs = eigsorted(cov)\n",
    "    theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))\n",
    "\n",
    "    # Width and height are \"full\" widths, not radius\n",
    "    \n",
    "    width, height = 2 * nstd * np.sqrt(vals)\n",
    "    ellip = Ellipse(xy=pos, width=width, height=height, angle=theta, **kwargs)\n",
    "\n",
    "    ax.add_artist(ellip)\n",
    "    return ellip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [(-2, -1), (1, 7), (4, 0), (5, 5)]\n",
    "fig, ax = plt.subplots(figsize = (10, 7))\n",
    "\n",
    "plt.xlim(-5, 10)\n",
    "plt.ylim(-5, 10)\n",
    "\n",
    "plt.title('Proyection Multivariate Normal')\n",
    "\n",
    "for k in range(4):\n",
    "    # samplear datos para visualizar cada elipse \n",
    "    points = np.random.multivariate_normal(mean=m[k], cov=[[1,0], [0,1]], size=500)\n",
    "\n",
    "    # definir elipse\n",
    "    plot_point_cov(points, nstd=2, alpha=0.3, color='r') #np.random.rand(3))\n",
    "        \n",
    "    plt.scatter(points[:, 0], points[:, 1])\n",
    "\n",
    "    plt.scatter(*m[k], color='black')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_normales = stt.norm.rvs(loc=0, scale=1, size=10000, random_state=None)\n",
    "\n",
    "datos_uniformes = stt.uniform.rvs(size=10000)\n",
    "\n",
    "datos_binom = stt.binom.rvs(1, 0.5, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(datos_normales, bins='auto')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(datos_binom, bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(datos_uniformes, bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consejos finales de eficiencia \n",
    "\n",
    "### Eficiencia en operaciones aritméticas \n",
    "\n",
    "En este curso una de las mayores dificultades será el optimizar procesos. Al trabajar con grandes cantidades de datos, los '_doble for_' y las listas por comprensión son muy ineficientes. Es por esta razón que para todas las operaciones que involucren recorrer toda la base de datos o realizar operaciones repetitivas, se deben usar `operaciones vectoriales`. Ellas están implementadas por _default_ en `numpy`. \n",
    "\n",
    "\n",
    "Por ejemplo, si se tiene una sumatoria de productos entre dos `arrays`, la lógica de intro/programación avanzada, nos dice que podríamos hacerlo con la ayuda de un `for`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista1 = np.random.rand(3)\n",
    "lista2 = np.random.rand(3)\n",
    "\n",
    "suma = 0 \n",
    "for i in range(3):\n",
    "    suma += lista1[i] * lista2[i] \n",
    "\n",
    "print(suma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funaciona bien! No obstante, debemos recordar que estamos trabajando con 3 datos :( En el caso de tener una base de datos más grande, digamos 1.000.000 datos, el panorama cambia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista1 = np.random.rand(1000000)\n",
    "lista2 = np.random.rand(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "suma = 0 \n",
    "for i in range(1000000):\n",
    "    suma += lista1[i] * lista2[i] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cambio, si llevamos esta operación a una vectorizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "np.dot(lista1, lista2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo1(x):\n",
    "    return (100 * x)**2 // 3\n",
    "\n",
    "\n",
    "def foo2(x):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suma1 = 0\n",
    "for i in range(1000000):\n",
    "    suma1 += foo1(lista1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suma2 = foo1(lista1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suma1 == suma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = [0.5, 1.6]\n",
    "cov_ = [[1,0], [0,1]]\n",
    "var = stt.multivariate_normal(mean=mu, cov=cov_)\n",
    "\n",
    "x = np.arange(-2, 4, 0.05)\n",
    "y = np.arange(-1, 6, 0.05)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "@np.vectorize\n",
    "def foo2(X_,Y_):\n",
    "    return var.pdf([X_,Y_])\n",
    "\n",
    "@np.vectorize\n",
    "def foo3(X_,Y_):\n",
    "    return stt.multivariate_normal(mean=mu, cov=cov_).pdf([X_,Y_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "foo2(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "foo3(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es fácil darse cuenta que el tiempo de ejecución en operaciones vectoriales es mucho menor. Es por ello que siempre que se está armando un algoritmo es recomendable primero armarlo con funciones familiares y nativas de `python` como `for` o `while`, pero luego, cuando el programa ya funcione correctamente, ir cambiado las operaciones a otras que involucren productos cruz, punto, inversiones, transposiciones, entre otras. \n",
    "\n",
    "### Eficiencia en manejos de Dataframes en Pandas \n",
    "\n",
    "Muchas veces tendremos que sumar, multiplicar, mover o cambiar un caracter en los elementos de entre las filas de un `Dataframe` de `Pandas`. Para ello, nos veremos tentados a usar el método `iterrows`. Mala idea. Este método trabaja igual que un `for` built-in. Como podemos intuir, para bases pequeñas funciona bien. Pero cuando tenemos bases más apegadas a la realidad, nuestro `iterrows` podría tardar meses. Es por esto que es altamente recomendado usar los métodos que nos ofrece `pandas` para manipular los `Dataframes`. Algunos ejemplos son: \n",
    "\n",
    "    - DataFrame.add (Suma un float a un dataframe o a cierta parte de éste) \n",
    "    - DataFrame.mul (Multiplica por un float)\n",
    "    - DataFrame.pow (Eleva el Dataframe) \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consejos finales de eficiencia \n",
    "\n",
    "### Eficiencia en operaciones aritméticas \n",
    "\n",
    "En este curso una de las mayores dificultades será el optimizar procesos. Al trabajar con grandes cantidades de datos, los '_doble for_' y las listas por comprensión son muy ineficientes. Es por esta razón que para todas las operaciones que involucren recorrer toda la base de datos o realizar operaciones repetitivas, se deben usar `operaciones vectoriales`. Ellas están implementadas por _default_ en `numpy`. \n",
    "\n",
    "\n",
    "Por ejemplo, si se tiene una sumatoria de productos entre dos `arrays`, la lógica de intro/programación avanzada, nos dice que podríamos hacerlo con la ayuda de un `for`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43897836296999826\n"
     ]
    }
   ],
   "source": [
    "lista1 = np.random.rand(3)\n",
    "lista2 = np.random.rand(3)\n",
    "\n",
    "suma = 0 \n",
    "for i in range(3):\n",
    "    suma += lista1[i] * lista2[i] \n",
    "\n",
    "print(suma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57848026, 0.35974705, 0.05163512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funaciona bien! No obstante, debemos recordar que estamos trabajando con 3 datos :( En el caso de tener una base de datos más grande, digamos 1.000.000 datos, el panorama cambia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.2 ms ± 416 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "lista1 = np.random.rand(1000000)\n",
    "lista2 = np.random.rand(1000000)\n",
    "\n",
    "suma = 0 \n",
    "for i in range(3):\n",
    "    suma += lista1[i] * lista2[i] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cambio, si llevamos esta operación a una vectorizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432 ns ± 68.4 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.dot(lista1, lista2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es fácil darse cuenta que el tiempo de ejecución en operaciones vectoriales es mucho menor. Es por ello que siempre que se está armando un algoritmo es recomendable primero armarlo con funciones familiares y nativas de `python` como `for` o `while`, pero luego, cuando el programa ya funcione correctamente, ir cambiado las operaciones a otras que involucren productos cruz, punto, inversiones, transposiciones, entre otras. \n",
    "\n",
    "### Eficiencia en manejos de Dataframes en Pandas \n",
    "\n",
    "Muchas veces tendremos que sumar, multiplicar, mover o cambiar un caracter en los elementos de entre las filas de un `Dataframe` de `Pandas`. Para ello, nos veremos tentados a usar el método `iterrows`. Mala idea. Este método trabaja igual que un `for` built-in. Como podemos intuir, para bases pequeñas funciona bien. Pero cuando tenemos bases más apegadas a la realidad, nuestro `iterrows` podría tardar meses. Es por esto que es altamente recomendado usar los métodos que nos ofrece `pandas` para manipular los `Dataframes`. Algunos ejemplos son: \n",
    "\n",
    "    - DataFrame.add (Suma un float a un dataframe o a cierta parte de éste) \n",
    "    - DataFrame.mul (Multiplica por un float)\n",
    "    - DataFrame.pow (Eleva el Dataframe) \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suma1 == suma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
